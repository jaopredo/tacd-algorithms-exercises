{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5f41198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656a883",
   "metadata": {},
   "source": [
    "# LAB 11 - Decision Trees for Classification\n",
    "\n",
    "Today, you will implement decision trees for classification using the Gini index as the splitting criterion. Youâ€™ll build the tree recursively, selecting splits that minimize Gini impurity and classifying samples based on majority class in each leaf. A good dataset to start with is the Iris dataset, which is small, well-labeled, and available directly via `sklearn.datasets.load_iris().`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca92acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fcff3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35e09f",
   "metadata": {},
   "source": [
    "We will focus only on binary classification today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f73cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[y != 2]\n",
    "y = y[y != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cfaf6707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d3bfd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=[i for i in range(X.shape[1])])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ec96c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_split, t_train, t_split = train_test_split(X, y, train_size=.6)\n",
    "X_validation, X_test, t_validation, t_test = train_test_split(X_split, t_split, train_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c57ab",
   "metadata": {},
   "source": [
    "## Please feel free to either use the code from last week as your structure, or any template you feel like works best for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cce741f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_criterion(region: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Implements the gini index criterion in a region\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region : pd.Series\n",
    "        Array of shape (N,) containing the values of the target values \n",
    "        for N datapoints in the training set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The sum of squared error\n",
    "        \n",
    "    Note\n",
    "    ----\n",
    "    The error for an empty region should be infinity (use: float(\"inf\"))\n",
    "    This avoids creating empty regions\n",
    "    \"\"\"\n",
    "    if len(region) == 0:\n",
    "        return float(\"inf\")\n",
    "    if isinstance(region, pd.Series):\n",
    "        region = region.to_numpy()\n",
    "    \n",
    "    classes = np.unique(region)\n",
    "    Gm = 0\n",
    "    \n",
    "    for k in classes:\n",
    "        p_mk = len(region[region == k]) / len(region)\n",
    "        Gm += p_mk * (1 - p_mk)\n",
    "\n",
    "    return Gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8bf9287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_region(region: pd.Series | pd.DataFrame, feature_index: int, tau: float):\n",
    "    \"\"\"\n",
    "    Given a region, splits it based on the feature indicated by\n",
    "    `feature_index`, the region will be split in two, where\n",
    "    one side will contain all points with the feature with values \n",
    "    lower than `tau`, and the other split will contain the \n",
    "    remaining datapoints.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region : pd.Series | pd.DataFrame\n",
    "        a partition of the dataset (or the full dataset) to be split\n",
    "    feature_index : int\n",
    "        the index of the feature (column of the region array) used to make this partition\n",
    "    tau : float\n",
    "        The threshold used to make this partition\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    left_partition : pd.Series | pd.DataFrame\n",
    "        indices of the datapoints in `region` where feature < `tau`\n",
    "    right_partition : pd.Series | pd.DataFrame\n",
    "        indices of the datapoints in `region` where feature >= `tau` \n",
    "    \"\"\"\n",
    "    left_partition = region[region[feature_index] < tau][feature_index].index\n",
    "    right_partition = region[region[feature_index] >= tau][feature_index].index\n",
    "\n",
    "    return left_partition, right_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "643be60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(X: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"\n",
    "    Given a dataset (full or partial), splits it on the feature of that minimizes the sum of squared error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        features \n",
    "    y : pd.Series\n",
    "        labels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    decision : dictionary\n",
    "        keys are:\n",
    "        * 'feature_index' -> an integer that indicates the feature (column) of `X` on which the data is split\n",
    "        * 'tau' -> the threshold used to make the split\n",
    "        * 'left_region' -> array of indices where the `feature_index`th feature of X is lower than `tau`\n",
    "        * 'right_region' -> indices not in `low_region`\n",
    "    \"\"\"\n",
    "    best_tau_separations = []\n",
    "    # List containing the best sse and tau registered for each feature, follows this structure\n",
    "\n",
    "    for feature in X.columns:  # Going through every feature\n",
    "        feature_gini = []\n",
    "        # List containing all registered SSE for this features (It follows this structure:)\n",
    "        # [ (tau_1, sse_1), (tau_2, sse_2), ..., (tau_j, sse_j) ]\n",
    "        # Where 'tau_i' is the ith element of the feature's column and 'sse_i' is its registered SSE\n",
    "        unique_features = pd.unique(X[feature])\n",
    "\n",
    "        for tau in unique_features:  # Using each value of the feature as tau (For performance reasons)\n",
    "            l_feature, r_feature = split_region(X, feature, tau)\n",
    "            gini_left = classification_criterion(y[l_feature])\n",
    "            gini_right = classification_criterion(y[r_feature])\n",
    "            feature_gini.append((tau, gini_left + gini_right))\n",
    "\n",
    "        minimum_tau_sse = min(feature_gini, key=lambda f_s: f_s[1])\n",
    "        # Getting the minimum SSE on feature_sses\n",
    "        best_tau_separations.append((feature, *minimum_tau_sse))\n",
    "    \n",
    "    best_separation_criterion = min(best_tau_separations, key=lambda s_c: s_c[2])\n",
    "\n",
    "    l, r = split_region(X, best_separation_criterion[0], best_separation_criterion[1])\n",
    "\n",
    "    return {\n",
    "        'feature_index': best_separation_criterion[0],\n",
    "        'tau': best_separation_criterion[1],\n",
    "        'left_region': l,\n",
    "        'right_region': r,\n",
    "        'gini_index': best_separation_criterion[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "688c9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_growth(\n",
    "    node: dict,\n",
    "    min_samples: int,\n",
    "    max_depth: int,\n",
    "    current_depth: int,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursively grows a decision tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : dictionary\n",
    "        If the node is terminal, it contains only the \"value\" key, which determines the value to be used as a prediction.\n",
    "        If the node is not terminal, the dictionary has the structure defined by `get_split`\n",
    "    min_samples : int\n",
    "        parameter for stopping criterion if a node has <= min_samples datapoints\n",
    "    max_depth : int\n",
    "        parameter for stopping criterion if a node belongs to this depth\n",
    "    depth : int\n",
    "        current distance from the root\n",
    "    X : pd.DataFrame\n",
    "        features (full dataset)\n",
    "    y : pd.Series\n",
    "        labels (full dataset)\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    To create a terminal node, a dictionary is created with a single \"value\" key, with a value that\n",
    "    is the mean of the target variable\n",
    "    \n",
    "    'left' and 'right' keys are added to non-terminal nodes, which contain (possibly terminal) nodes \n",
    "    from higher levels of the tree:\n",
    "    'left' corresponds to the 'left_region' key, and 'right' to the 'right_region' key\n",
    "    \"\"\"\n",
    "    l_idx = node['left_region']\n",
    "    r_idx = node['right_region']\n",
    "\n",
    "    if                                                                                  \\\n",
    "        (len(X) <= min_samples)             \\\n",
    "        or                                                                              \\\n",
    "        (current_depth >= max_depth)                                                    \\\n",
    "    :\n",
    "        return {\n",
    "            \"value\": np.mean(y)\n",
    "        }\n",
    "    \n",
    "    # X = X.drop(node['feature_index'], axis=1)\n",
    "    splited_infos = get_split(X, y)\n",
    "    l_idx = splited_infos['left_region']\n",
    "    r_idx = splited_infos['right_region']\n",
    "    \n",
    "    return {\n",
    "        'feature_index': splited_infos['feature_index'],\n",
    "        'tau': splited_infos['tau'],\n",
    "        'left': recursive_growth(splited_infos, min_samples, max_depth, current_depth+1, X.loc[l_idx], y.loc[l_idx]),\n",
    "        'right': recursive_growth(splited_infos, min_samples, max_depth, current_depth+1, X.loc[r_idx], y.loc[r_idx])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c2407bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will test 3 values for min_samples_split: 2, 4, 6\n",
    "# Remember that this sets the minimum number of samples required in a node to be eligible for splitting. \n",
    "# These values are good for small datasets like Iris, but you can try other values for larger datasets to not make the tree too deep.\n",
    "\n",
    "max_depth = 6\n",
    "min_samples_tests = [2, 4, 6]\n",
    "trees = []\n",
    "\n",
    "for sample in min_samples_tests:\n",
    "    root = get_split(X_train, t_train)\n",
    "    tree_root = recursive_growth(root, sample, max_depth, 0, X_train, t_train)\n",
    "    trees.append(tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fee8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth):\n",
    "    if 'value' in node.keys():\n",
    "        print('.  '*(depth-1), f\"[{node['value']}]\")\n",
    "    else:\n",
    "        print('.  '*depth, f'X_{node[\"feature_index\"]} < {node[\"tau\"]}')\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "27f583e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_2 < 3.0\n",
      ".   X_0 < 5.4\n",
      ".  .   X_0 < 5.0\n",
      ".  .  .   X_0 < 4.6\n",
      ".  .  .   [0.0]\n",
      ".  .  .  .   X_0 < 4.8\n",
      ".  .  .  .  .   X_0 < 4.7\n",
      ".  .  .  .  .   [0.0]\n",
      ".  .  .  .  .   [0.0]\n",
      ".  .  .  .  .   X_1 < 3.4\n",
      ".  .  .  .  .   [0.0]\n",
      ".  .  .  .  .   [0.0]\n",
      ".  .  .   X_0 < 5.1\n",
      ".  .  .  .   X_1 < 3.5\n",
      ".  .  .  .   [0.0]\n",
      ".  .  .  .   [0.0]\n",
      ".  .  .  .   X_0 < 5.2\n",
      ".  .  .  .  .   X_1 < 3.4\n",
      ".  .  .  .  .   [0.0]\n",
      ".  .  .  .  .   [0.0]\n",
      ".  .  .  .   [0.0]\n",
      ".  .   X_0 < 5.5\n",
      ".  .  .   X_1 < 3.9\n",
      ".  .  .   [0.0]\n",
      ".  .  .   [0.0]\n",
      ".  .  .   X_0 < 5.7\n",
      ".  .  .   [0.0]\n",
      ".  .  .   [0.0]\n",
      ".   X_0 < 6.2\n",
      ".  .   X_0 < 6.0\n",
      ".  .  .   X_0 < 5.5\n",
      ".  .  .  .   X_0 < 5.0\n",
      ".  .  .  .   [1.0]\n",
      ".  .  .  .  .   X_0 < 5.2\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .   X_0 < 5.7\n",
      ".  .  .  .  .   X_0 < 5.6\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .  .   X_0 < 5.9\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .   X_0 < 6.1\n",
      ".  .  .  .   X_1 < 3.4\n",
      ".  .  .  .  .   X_1 < 2.7\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .   [1.0]\n",
      ".  .  .   [1.0]\n",
      ".  .   X_0 < 6.8\n",
      ".  .  .   X_0 < 6.4\n",
      ".  .  .  .   X_0 < 6.3\n",
      ".  .  .  .   [1.0]\n",
      ".  .  .  .  .   X_1 < 2.5\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .   X_0 < 6.6\n",
      ".  .  .  .  .   X_0 < 6.5\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .  .   [1.0]\n",
      ".  .  .  .   [1.0]\n",
      ".  .   [1.0]\n"
     ]
    }
   ],
   "source": [
    "print_tree(trees[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cf734",
   "metadata": {},
   "source": [
    "Use accuracy to find the best split. Don't import it from sklearn, calculate it yourself, it's a one-liner ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "40b8ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(node: dict, sample: pd.Series):\n",
    "    \"\"\"\n",
    "    Makes a prediction based on the decision tree defined by `node`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : dictionary\n",
    "        A node created one of the methods above\n",
    "    sample : array of size (n_features,)\n",
    "        a sample datapoint\n",
    "    \"\"\"\n",
    "    if 'value' in node.keys():\n",
    "        return node['value']\n",
    "    else:\n",
    "        if sample[node['feature_index']] < node['tau']:\n",
    "            return predict_sample(node['left'], sample)\n",
    "        else:\n",
    "            return predict_sample(node['right'], sample)\n",
    "\n",
    "\n",
    "def predict(node, X):\n",
    "    \"\"\"\n",
    "    Makes a prediction based on the decision tree defined by `node`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : dictionary\n",
    "        A node created one of the methods above\n",
    "    X : array of size (n_samples, n_features)\n",
    "        n_samples predictions will be made\n",
    "    \"\"\"\n",
    "    predicted_values = pd.Series(np.array([x for x in range(len(X))]))\n",
    "\n",
    "    predicted_values = predicted_values.apply(lambda i: predict_sample(node, X.iloc[i]))\n",
    "\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6de25e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(t: pd.Series, y: pd.Series) -> float:\n",
    "    \"\"\"Gets the precision using the passed parameters\n",
    "\n",
    "    Args\n",
    "    ----------\n",
    "    t: pd.Series\n",
    "        True labels\n",
    "    y: pd.Series\n",
    "        Predictions\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    float: The precision of the given prediction\n",
    "    \"\"\"\n",
    "    y = y.to_numpy()\n",
    "    t = t.to_numpy()\n",
    "    TP = len(y[\n",
    "        (y == 1) & (t == 1  )\n",
    "    ])\n",
    "    FP = len(y[\n",
    "        (y == 1) & (t == 0)\n",
    "    ])\n",
    "    if TP + FP == 0:\n",
    "        return 0\n",
    "    precision = TP / (TP + FP)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ffd6a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Getting the best min sample\n",
    "precisions = []\n",
    "for tree_root in trees:\n",
    "    y_validation = predict(tree_root, X_validation)\n",
    "    precisions.append(get_precision(t_validation, y_validation))\n",
    "\n",
    "# Checking if we don't have equal probabilities\n",
    "last_value = None\n",
    "all_equal = True\n",
    "for value in precisions:\n",
    "    if not last_value:\n",
    "        last_value = value\n",
    "        continue\n",
    "    \n",
    "    if value != last_value:\n",
    "        all_equal = False\n",
    "\n",
    "best_min_samples = 0\n",
    "\n",
    "if all_equal:\n",
    "    best_min_samples = min_samples_tests[-1]\n",
    "else:\n",
    "    min_precision = min(precisions)\n",
    "    best_min_samples = min_samples_tests[precisions.index(min_precision)]\n",
    "\n",
    "best_min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5150cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.concat([X_train, X_validation], axis=0)\n",
    "new_target = pd.concat([t_train, t_validation], axis=0)\n",
    "root = get_split(new_dataset, new_target)\n",
    "tree_root = recursive_growth(root, best_min_samples, max_depth, 0, new_dataset, new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0b004968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = predict(tree_root, X_test)\n",
    "get_precision(t_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
